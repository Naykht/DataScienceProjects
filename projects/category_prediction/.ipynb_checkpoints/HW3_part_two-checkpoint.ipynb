{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BVrrwTJNjuDt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BqEuoDhqNgoa",
    "outputId": "9a05c421-1c99-4625-f0da-819350b9d7a0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>Category_name</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>382220</th>\n",
       "      <td>Прихожая</td>\n",
       "      <td>В хорошем состоянии. Торг</td>\n",
       "      <td>Мебель и интерьер</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397529</th>\n",
       "      <td>Кордиант 215/55/16 Летние</td>\n",
       "      <td>Кордиант 215/55/16 Летние/\\n /\\nАртикул: 1737l...</td>\n",
       "      <td>Запчасти и аксессуары</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584569</th>\n",
       "      <td>Стол</td>\n",
       "      <td>Стол, 2 рабочих места . Стол серого цвета, в д...</td>\n",
       "      <td>Мебель и интерьер</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513100</th>\n",
       "      <td>Комбинезон</td>\n",
       "      <td>Размер-42/44</td>\n",
       "      <td>Одежда, обувь, аксессуары</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091886</th>\n",
       "      <td>Ветровка</td>\n",
       "      <td>На 2 года</td>\n",
       "      <td>Детская одежда и обувь</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title  \\\n",
       "id                                   \n",
       "382220                    Прихожая   \n",
       "397529   Кордиант 215/55/16 Летние   \n",
       "584569                        Стол   \n",
       "2513100                 Комбинезон   \n",
       "1091886                   Ветровка   \n",
       "\n",
       "                                               description  \\\n",
       "id                                                           \n",
       "382220                           В хорошем состоянии. Торг   \n",
       "397529   Кордиант 215/55/16 Летние/\\n /\\nАртикул: 1737l...   \n",
       "584569   Стол, 2 рабочих места . Стол серого цвета, в д...   \n",
       "2513100                                       Размер-42/44   \n",
       "1091886                                          На 2 года   \n",
       "\n",
       "                     Category_name  Category  \n",
       "id                                            \n",
       "382220           Мебель и интерьер        20  \n",
       "397529       Запчасти и аксессуары        10  \n",
       "584569           Мебель и интерьер        20  \n",
       "2513100  Одежда, обувь, аксессуары        27  \n",
       "1091886     Детская одежда и обувь        29  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/kaggle/input/train_subset.csv\", index_col='id')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Kg8iPp7fiwGh",
    "outputId": "ed52d9fa-831c-4617-cec6-cb5c5def7631"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "A1hvzAMETU2d"
   },
   "outputs": [],
   "source": [
    "X = data[['title', 'description']].to_numpy()\n",
    "y = data['Category'].to_numpy()\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6fia4_3vNprp"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "AWs6NRsRXIdQ"
   },
   "outputs": [],
   "source": [
    "def frequency_words(X):\n",
    "    counter_words = {}\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            for word in X[i][j].split(' '):\n",
    "                word = word.strip(' ')\n",
    "                if word in counter_words:\n",
    "                    counter_words[word] += 1\n",
    "                else:\n",
    "                    counter_words[word] = 1\n",
    "    return counter_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "4awkhecbR9om"
   },
   "outputs": [],
   "source": [
    "def text_to_bow(text: str) -> np.array:\n",
    "    \"\"\"\n",
    "    Возвращает вектор, где для каждого слова из bow_vocabulary\n",
    "    указано количество его употреблений\n",
    "    \"\"\" \n",
    "    zero_vector = {}\n",
    "    for i in bow_vocabulary:\n",
    "        zero_vector[i] = 0\n",
    "    \n",
    "    for word in text.split(' '):\n",
    "        word = word.strip(' ')\n",
    "        if word in zero_vector:\n",
    "            zero_vector[word] += 1\n",
    "    \n",
    "    return np.array(list(zero_vector.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "HR_D8Fn4pudv"
   },
   "outputs": [],
   "source": [
    "def items_to_bow(items: np.array) -> np.array:\n",
    "    \"\"\" Для каждого товара возвращает вектор его bow \"\"\"\n",
    "    # Давайте для начала попробуем строить bow только из description товара\n",
    "    # assert ниже написан для bow из description\n",
    "    \n",
    "    items_bow = []\n",
    "    for item in range(len(items)):\n",
    "        item_bow = text_to_bow(items[item][1])\n",
    "        items_bow.append(item_bow)\n",
    "    return np.array(items_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "evqKo1r5L5BO"
   },
   "outputs": [],
   "source": [
    "def items_to_bow_full(items: np.array) -> np.array:\n",
    "    items_bow = []\n",
    "    for item in range(items.shape[0]):\n",
    "        item_bow_title = text_to_bow(items[item][0])\n",
    "        item_bow_desc = text_to_bow(items[item][1])\n",
    "        item_bow = item_bow_title + item_bow_desc\n",
    "        items_bow.append(item_bow)\n",
    "    return np.array(items_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvCAL3qGDByj"
   },
   "source": [
    "### mystem (1.5) балла\n",
    "\n",
    "Попробуйте обучиться, используя токенизатор mystem. Сравните качество.\n",
    "Как можно заметить, в текстах одни и те же слова могут быть в разных падежах, а соответственно в bow это будут разные признаки. Чтобы исправить это, можно лемматизировать слова - с помощью библиотеки Mystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "60oQ-6UgDcLF",
    "outputId": "cb3dbc32-d1f1-46ab-a4ad-e007cdd4a6ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymystem3 in /opt/conda/lib/python3.6/site-packages (0.2.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from pymystem3) (2.22.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->pymystem3) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->pymystem3) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->pymystem3) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->pymystem3) (2019.11.28)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mGvNHfVsDfhq"
   },
   "outputs": [],
   "source": [
    "mystem = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "wh2oQQVIXIei"
   },
   "outputs": [],
   "source": [
    "def preprocess_my(text: str) -> str:\n",
    "    return ' '.join(mystem.lemmatize(text.lower()))\n",
    "\n",
    "def tokenize_X_my(X):\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            X[i][j] = preprocess_my(X[i][j])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ka_EugqpXIel",
    "outputId": "794f9a9d-9a3c-4d92-8476-c6aac67b19e6"
   },
   "outputs": [],
   "source": [
    "X_train_my = tokenize_X_my(X_train)\n",
    "X_test_my = tokenize_X_my(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "xQ5iKeErXIer"
   },
   "outputs": [],
   "source": [
    "bow_vocabulary = frequency_words(X_train_my)\n",
    "bow_vocabulary = sorted(bow_vocabulary, key=bow_vocabulary.get, reverse=True)[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "qGtS7M1XbSDB"
   },
   "outputs": [],
   "source": [
    "X_train_bow_my = items_to_bow_full(X_train_my)\n",
    "X_test_bow_my = items_to_bow_full(X_test_my)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVeso3TGet02"
   },
   "source": [
    "#### Logistic Regression (при использовании mystem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "aWojJesCe7Qg",
    "outputId": "8caf8d76-42ca-4589-ce9c-01f9c583f564"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44\n"
     ]
    }
   ],
   "source": [
    "bow_model = LogisticRegression().fit(X_train_bow_my, y_train)\n",
    "print(accuracy_score(bow_model.predict(X_test_bow_my), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BvOFKUSWekfK"
   },
   "source": [
    "#### SVM (при использовании mystem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "bF-m8vFveejO",
    "outputId": "1d17148e-850d-4f28-c231-921c3c0d204e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7744444444444445\n"
     ]
    }
   ],
   "source": [
    "bow_model = LinearSVC().fit(X_train_bow_my, y_train)\n",
    "print(accuracy_score(bow_model.predict(X_test_bow_my), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** качество моделей упало, особенно у LR - с 0.66 до 0.44, а у SVC качество снизилос незначительно с 0.79 до 0.77."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXbsPtpfoB7m"
   },
   "source": [
    "### TF-IDF (1.5 балла)\n",
    "\n",
    "Не все слова полезны одинаково, давайте попробуем [взвесить](http://tfidf.com/) их, чтобы отобрать более полезные.\n",
    "\n",
    "\n",
    "> TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).\n",
    "> \n",
    "> IDF(t) = log_e(Total number of documents / Number of documents with term t in it).\n",
    "\n",
    "\n",
    "В sklearn есть TfidfVectorizer, но в этом задании его использовать нельзя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитаем idf для всех товаров на X_train_my\n",
    "\n",
    "\"\"\"\n",
    "# Считаем количество того, в скольких документах встретилось каждое из слов из bow_vocabulary\n",
    "\"\"\"\n",
    "\n",
    "document_freq = {}\n",
    "for bow_word in bow_vocabulary:\n",
    "    document_freq[bow_word] = 0\n",
    "\n",
    "\n",
    "for bow_word in bow_vocabulary:\n",
    "    for item in X_train_my:\n",
    "        text = item[0] + ' ' + item[1]\n",
    "        if bow_word in text:\n",
    "            document_freq[bow_word] += 1\n",
    "\n",
    "\"\"\"\n",
    "# Расчет для idf\n",
    "\"\"\"\n",
    "\n",
    "bow_word_counter = []\n",
    "idx_bow_words = {}\n",
    "idx = 0\n",
    "for bow_word, count in document_freq.items():\n",
    "    bow_word_counter.append(count)\n",
    "    idx_bow_words[bow_word] = idx\n",
    "    idx += 1\n",
    "\n",
    "idf_vector = np.log(X.shape[0] / np.array(bow_word_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(X):\n",
    "\n",
    "    \"\"\"\n",
    "    Расчет для tf\n",
    "    \"\"\"\n",
    "    \n",
    "    tf_matrix = []\n",
    "    for item in X:\n",
    "        tf_item = np.zeros(len(bow_vocabulary))\n",
    "        text = item[0] + ' ' + item[1]\n",
    "        for word in text.split(' '):\n",
    "            if word in bow_vocabulary:\n",
    "                idx_bow = idx_bow_words[word]\n",
    "                tf_item[idx_bow] += 1\n",
    "        tf_item = tf_item / item.shape[0]\n",
    "        tf_matrix.append(tf_item)\n",
    "\n",
    "    return np.array(tf_matrix) * idf_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf(X_train_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf = tfidf(X_test_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "LvL9BH7DsJrv"
   },
   "outputs": [],
   "source": [
    "# Нормализуйте данные\n",
    "\n",
    "X_train_tfidf_norm = normalize(X_train_tfidf)\n",
    "X_test_tfidf_norm = normalize(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YFA-8kE1RHk"
   },
   "source": [
    "### Модели на TF-IDF признаках (1 балл)\n",
    "\n",
    "Обучите логистическую регрессию и SVC, оцените качество (accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression (после TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "-ULrXsF1m5sU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7635555555555555\n"
     ]
    }
   ],
   "source": [
    "bow_model = LogisticRegression().fit(X_train_tfidf_norm, y_train)\n",
    "print(accuracy_score(bow_model.predict(X_test_tfidf_norm), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC (после TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83\n"
     ]
    }
   ],
   "source": [
    "bow_model = LinearSVC().fit(X_train_tfidf_norm, y_train)\n",
    "print(accuracy_score(bow_model.predict(X_test_tfidf_norm), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вывод__: качество возразло сильно у LR с 0.44 до 0.76, а у SVC с 0.77 до 0.83."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFdy3lUFDsOr"
   },
   "source": [
    "### Hashing Vectorizer (0.5 балла)\n",
    "\n",
    "Попробуйте использовать `sklearn.feature_extraction.text.HashingVectorizer` для векторизации текстов.\n",
    "Обязательно оцените качество работы алгоритмов классификации с использованием новой векторизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv = HashingVectorizer(n_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_X(X):\n",
    "    X_new = []\n",
    "    for item in X:\n",
    "        X_new.append(item[0] + ' ' + item[1])\n",
    "    return np.array(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_my_conc = concat_X(X_train_my)\n",
    "X_test_my_conc = concat_X(X_test_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Y666HTrqDq1m"
   },
   "outputs": [],
   "source": [
    "X_train_hv = hv.fit_transform(X_train_my_conc)\n",
    "X_test_hv = hv.fit_transform(X_test_my_conc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression (после Hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7542222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "bow_model = LogisticRegression().fit(X_train_hv, y_train)\n",
    "print(accuracy_score(bow_model.predict(X_test_hv), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC (после Hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8095555555555556\n"
     ]
    }
   ],
   "source": [
    "bow_model = LinearSVC().fit(X_train_hv, y_train)\n",
    "print(accuracy_score(bow_model.predict(X_test_hv), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вывод__: качество чуть-чуть подупало: у LR с 0.76 до 0.755, а у SVC - с 0.83 до 0.81."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQZ61xSsTpZI"
   },
   "source": [
    "### Word Vectors (1.5 балл)\n",
    "\n",
    "Давайте попробуем другой подход -- кажому слову сопоставим какой-то эмбеддинг (вектор).\n",
    "\n",
    "Вектора будут небольшой размерности. Таким образом мы снизим количество параметров в модели.\n",
    "\n",
    "Вектора мы возьмём уже готовые (обученные на текстах изинтернета), так что наша модель будет знать некоторую дополнительную информацию о внешнем мире."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "T38J27NcYGx5",
    "outputId": "57fa3a9f-13a3-4fa1-d13c-3c0c49a86a71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-24 17:28:36--  https://www.dropbox.com/s/0x7oxso6x93efzj/ru.tar.gz\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:601b:1::a27d:801\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/0x7oxso6x93efzj/ru.tar.gz [following]\n",
      "--2020-04-24 17:28:37--  https://www.dropbox.com/s/raw/0x7oxso6x93efzj/ru.tar.gz\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc9c5142e2c0254c4d3dfa5c886b.dl.dropboxusercontent.com/cd/0/inline/A2cH8oDrMetX-LbrBdwDUPbYQIupRqSdik9bNbGdBwIcNUeGLae4lszQoepDD4-hbrD3hJ65tJI5b5vIFpnl8yDEPmcxmZCi2uMKk8fcPMOnXQ/file# [following]\n",
      "--2020-04-24 17:28:37--  https://uc9c5142e2c0254c4d3dfa5c886b.dl.dropboxusercontent.com/cd/0/inline/A2cH8oDrMetX-LbrBdwDUPbYQIupRqSdik9bNbGdBwIcNUeGLae4lszQoepDD4-hbrD3hJ65tJI5b5vIFpnl8yDEPmcxmZCi2uMKk8fcPMOnXQ/file\n",
      "Resolving uc9c5142e2c0254c4d3dfa5c886b.dl.dropboxusercontent.com (uc9c5142e2c0254c4d3dfa5c886b.dl.dropboxusercontent.com)... 162.125.8.6, 2620:100:601b:6::a27d:806\n",
      "Connecting to uc9c5142e2c0254c4d3dfa5c886b.dl.dropboxusercontent.com (uc9c5142e2c0254c4d3dfa5c886b.dl.dropboxusercontent.com)|162.125.8.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 FOUND\n",
      "Location: /cd/0/inline2/A2eL5TbNTNNknXZiMWehf6r4gDJqyFzeU3HOK6seywqwNR1SP2YWubgdC4cxz_eOtzFYOj6WVc1kw4jg2trof7GItzPadPMd4StNQOp9eks5dl557XAlgEzP7V3ugazRFTkSRzVqozd0MwIx9njQpnz12vHxeJlEJae8gB5rPqLERbek61pKTVPubyMs5_5ljNAIKg4tq7wawUxGI0yMlAZ_devMFzKbm9pzUoVgFrpew4Ellu0uBnx8BYOYZRoUNe051RJzaVblSJSN8G6k5XoiXSEcq2hX1thtnd9ptEEsfjGQ798S8F41OpDbFCzIB59BAgeoIN1_OD0kjTXMRBk6/file [following]\n",
      "--2020-04-24 17:28:38--  https://uc9c5142e2c0254c4d3dfa5c886b.dl.dropboxusercontent.com/cd/0/inline2/A2eL5TbNTNNknXZiMWehf6r4gDJqyFzeU3HOK6seywqwNR1SP2YWubgdC4cxz_eOtzFYOj6WVc1kw4jg2trof7GItzPadPMd4StNQOp9eks5dl557XAlgEzP7V3ugazRFTkSRzVqozd0MwIx9njQpnz12vHxeJlEJae8gB5rPqLERbek61pKTVPubyMs5_5ljNAIKg4tq7wawUxGI0yMlAZ_devMFzKbm9pzUoVgFrpew4Ellu0uBnx8BYOYZRoUNe051RJzaVblSJSN8G6k5XoiXSEcq2hX1thtnd9ptEEsfjGQ798S8F41OpDbFCzIB59BAgeoIN1_OD0kjTXMRBk6/file\n",
      "Reusing existing connection to uc9c5142e2c0254c4d3dfa5c886b.dl.dropboxusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2399456034 (2.2G) [application/octet-stream]\n",
      "Saving to: ‘ru.tar.gz.2’\n",
      "\n",
      "ru.tar.gz.2           0%[                    ]       0  --.-KB/s    in 0s      \n",
      "\n",
      "\n",
      "Cannot write to ‘ru.tar.gz.2’ (No space left on device).\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/0x7oxso6x93efzj/ru.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "Zfse4xVbgMIr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: ru.vec: Wrote only 5632 of 8861 bytes\r\n",
      "tar: Exiting with failure status due to previous errors\r\n"
     ]
    }
   ],
   "source": [
    "!tar -xzf ru.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook_source__.ipynb  ru.bin  ru.tar.gz  ru.tar.gz.1  ru.tar.gz.2\tru.vec\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "sy2TXmQ2jZSY"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.wrappers import FastText\n",
    "\n",
    "\n",
    "model = FastText.load_fasttext_format('ru.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "H49QR_jhjmCa"
   },
   "outputs": [],
   "source": [
    "# Эмбеддинг предложения -- сумма эмбеддингов токенов\n",
    "\n",
    "\n",
    "def sentence_embedding(sentence: str) -> np.array:\n",
    "    \"\"\"\n",
    "    Складывает вектора токенов строки sentence\n",
    "    \"\"\"\n",
    "\n",
    "    embedding_dim = model['кек'].shape[0]\n",
    "    features = np.zeros([embedding_dim], dtype='float32')\n",
    "    \n",
    "    for word in sentence.split():\n",
    "        if word in model:\n",
    "            features += model[word]\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Gj6U_hjtlllV"
   },
   "outputs": [],
   "source": [
    "assert np.allclose(sentence_embedding('сдаётся уютный , тёплый гараж для стартапов в ml')[::50],\n",
    "                   np.array([ 0.08189847,  0.07249198, -0.15601222,  0.03782297,  0.09215296, -0.23092946]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding(X) -> np.array:\n",
    "        \n",
    "    embedding_dim = model['кек'].shape[0]\n",
    "    \n",
    "    X_embed = []\n",
    "    for item in X:\n",
    "        features = np.zeros([embedding_dim], dtype='float32')\n",
    "        text = item[0] + ' ' + item[1]\n",
    "        for word in text.split(' '):\n",
    "            if word in model:\n",
    "                features += model[word]\n",
    "        X_embed.append(features)\n",
    "\n",
    "    return np.array(X_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_embed = embedding(X_train_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_embed = embedding(X_test_my)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression (после Word Vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5828888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "bow_model = LogisticRegression().fit(X_train_embed, y_train)\n",
    "print(accuracy_score(bow_model.predict(X_test_embed), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC (после Word Vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6145555555555555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "bow_model = LinearSVC().fit(X_train_embed, y_train)\n",
    "print(accuracy_score(bow_model.predict(X_test_embed), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вывод__: по сравнению с качеством на Hash: качество резко упало у обоих моделей: у LR - с 0.755 до 0.58, а у SVC - 0.81 до 0.61."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
